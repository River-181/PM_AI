{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732629ab",
   "metadata": {},
   "source": [
    "\n",
    "# ì†Œë¦¬â†’ë¹› ë²ˆì—­ AI ëª¨ë¸ ê°œë°œ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ê°€ì • ë‚´ ìƒí™œ ì†Œë¦¬ ë¶„ë¥˜**ë¥¼ ìœ„í•´ ì „ì´í•™ìŠµ(EfficientNetB0)ê³¼ **ë¡œê·¸-ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "íë¦„: **ë°ì´í„° ì¤€ë¹„ â†’ ì „ì²˜ë¦¬(ìŠ¬ë¼ì´ë”© ìœˆë„ìš°) â†’ í•™ìŠµ â†’ íŒŒì¼/ì‹¤ì‹œê°„ ì¶”ë¡ **\n",
    "\n",
    "- ë¶„ë¥˜ ëŒ€ìƒ(6ì¢…): í™”ì¬ê²½ë³´, ì´ˆì¸ì¢…/ë…¸í¬/ë„ì–´ë½, ì „í™”ë²¨/ì•Œë¦¼, ê°€ì „ì œí’ˆ ì™„ë£ŒìŒ, ì•„ì´ ìš¸ìŒ/ê°•ì•„ì§€ ì§–ìŒ, ë°œì†Œë¦¬/ì¶©ê²©ìŒ  \n",
    "- ìƒ‰ìƒ ë§¤í•‘: ë¹¨ê°•/ì£¼í™©/ë…¸ë‘/ì´ˆë¡/íŒŒë‘/ë³´ë¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd13cf",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜ (í•„ìš” ì‹œ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Colab/ìƒˆ í™˜ê²½ì´ë¼ë©´ ì‹¤í–‰)\n",
    "# !pip install numpy scipy librosa==0.10.2.post1 soundfile sounddevice matplotlib tensorflow==2.15.* tensorflow-io==0.36.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd149851",
   "metadata": {},
   "source": [
    "## âš™ï¸ ì„í¬íŠ¸ & ê³µí†µ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c69b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n",
      "ğŸ“š ë¡œë“œëœ í´ë˜ìŠ¤: 21ê°œ\n",
      "   ê°€ì „ì œí’ˆ_ì¢…ë£Œ, ê°œ, ë¬¸_ë…¸í¬, ë¬¸_ë„ì–´ë½, ë¬¸_ì´ˆì¸ì¢…...ë“±ë“±\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json, time, queue, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import zoom\n",
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "\n",
    "# ==== ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„° ====\n",
    "SR = 16000               # ìƒ˜í”Œë ˆì´íŠ¸\n",
    "WIN_SEC = 1.0            # ìœˆë„ìš° ê¸¸ì´ (ì´ˆ)\n",
    "HOP_SEC = 0.5            # ìŠ¬ë¼ì´ë”© ìŠ¤í… (ì´ˆ)\n",
    "N_MELS = 64              # ë©œ ë°´ë“œ ìˆ˜\n",
    "FMIN, FMAX = 50, 8000    # ì£¼íŒŒìˆ˜ ëŒ€ì—­\n",
    "SPEC_SHAPE = (128, 128)  # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "DATA_DIR = \"..\"\n",
    "CACHE_DIR = \"../cache\"\n",
    "MODEL_DIR = \"../models\"\n",
    "Path(CACHE_DIR).mkdir(exist_ok=True)\n",
    "Path(MODEL_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "# ==================== í•œê¸€ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ====================\n",
    "# eda_and_model_selection_v2.ipynbì™€ ë™ì¼í•˜ê²Œ ì„¤ì •\n",
    "CLASSES = [\n",
    "    \"ê°€ì „ì œí’ˆ_ì¢…ë£Œ\",\n",
    "    \"ê°œ\",\n",
    "    \"ë¬¸_ë…¸í¬\",\n",
    "    \"ë¬¸_ë„ì–´ë½\",\n",
    "    \"ë¬¸_ì´ˆì¸ì¢…\",\n",
    "    \"ë°°ê²½ì†ŒìŒ\",\n",
    "    \"ì†ŒìŒ_ê°€êµ¬\",\n",
    "    \"ì†ŒìŒ_ë“œëŸ¼\",\n",
    "    \"ì†ŒìŒ_ë¬¸ì†Œë¦¬\",\n",
    "    \"ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬\",\n",
    "    \"ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬\",\n",
    "    \"ì†ŒìŒ_ì²­ì†Œê¸°\",\n",
    "    \"ì†ŒìŒ_í†µëŒì´\",\n",
    "    \"ì•„ê¸°_ìš¸ìŒ\",\n",
    "    \"ì•ˆì „_ë‚™ìƒ\",\n",
    "    \"ì•ˆì „_í™”ì¬_ê²½ë³´\",\n",
    "    \"ì •ì \",\n",
    "    \"íƒ€ì´ë¨¸_ì•ŒëŒ\",\n",
    "    \"í°_ë§í†¤\",\n",
    "    \"í°_ì•Œë¦¼\",\n",
    "    \"í°_ì „í™”\",\n",
    "]\n",
    "\n",
    "# ==================== ìƒ‰ìƒ ë§¤í•‘ (ì¹´í…Œê³ ë¦¬ë³„) ====================\n",
    "# ëŒ€í‘œ ê·¸ë£¹ë³„ ìƒ‰ìƒ ì§€ì •\n",
    "# | ëŒ€í‘œ ê·¸ë£¹ | í•˜ìœ„ í´ë” ì˜ˆì‹œ             | ìƒ‰ìƒ    |\n",
    "# | ----- | -------------------- | ----- |\n",
    "# | ì•ˆì „ ê´€ë ¨ | ì•ˆì „_ë‚™ìƒ, ì•ˆì „_í™”ì¬_ê²½ë³´      | ğŸ”´ ë¹¨ê°• |\n",
    "# | ë¬¸ ê´€ë ¨  | ë¬¸_ë…¸í¬, ë¬¸_ë„ì–´ë½, ë¬¸_ì´ˆì¸ì¢…   | ğŸŸ  ì£¼í™© |\n",
    "# | ì•Œë¦¼ ê´€ë ¨ | íƒ€ì´ë¨¸_ì•ŒëŒ, í°_ì•Œë¦¼, í°_ì „í™”   | ğŸŸ¡ ë…¸ë‘ |\n",
    "# | ê°€ì „ ê´€ë ¨ | ê°€ì „ì œí’ˆ_ì¢…ë£Œ, ì†ŒìŒ_ì²­ì†Œê¸°      | ğŸŸ¢ ì´ˆë¡ |\n",
    "# | ì‚¬ëŒÂ·ë™ë¬¼ | ì•„ê¸°_ìš¸ìŒ, ê°œ                | ğŸ”µ íŒŒë‘ |\n",
    "# | ì¼ë°˜ ì†ŒìŒ | ì†ŒìŒ_ê°€êµ¬, ì†ŒìŒ_ë“œëŸ¼, ì†ŒìŒ_ë°œì†Œë¦¬ | ğŸŸ£ ë³´ë¼ |\n",
    "\n",
    "CLASS_TO_COLOR = {\n",
    "    # ğŸ”´ ì•ˆì „ ê´€ë ¨\n",
    "    \"ì•ˆì „_ë‚™ìƒ\": \"RED\",\n",
    "    \"ì•ˆì „_í™”ì¬_ê²½ë³´\": \"RED\",\n",
    "    \n",
    "    # ğŸŸ  ë¬¸ ê´€ë ¨\n",
    "    \"ë¬¸_ë…¸í¬\": \"ORANGE\",\n",
    "    \"ë¬¸_ë„ì–´ë½\": \"ORANGE\",\n",
    "    \"ë¬¸_ì´ˆì¸ì¢…\": \"ORANGE\",\n",
    "    \n",
    "    # ğŸŸ¡ ì•Œë¦¼ ê´€ë ¨\n",
    "    \"íƒ€ì´ë¨¸_ì•ŒëŒ\": \"YELLOW\",\n",
    "    \"í°_ë§í†¤\": \"YELLOW\",\n",
    "    \"í°_ì•Œë¦¼\": \"YELLOW\",\n",
    "    \"í°_ì „í™”\": \"YELLOW\",\n",
    "    \n",
    "    # ğŸŸ¢ ê°€ì „ ê´€ë ¨\n",
    "    \"ê°€ì „ì œí’ˆ_ì¢…ë£Œ\": \"GREEN\",\n",
    "    \"ì†ŒìŒ_ì²­ì†Œê¸°\": \"GREEN\",\n",
    "    \n",
    "    # ğŸ”µ ì‚¬ëŒÂ·ë™ë¬¼\n",
    "    \"ì•„ê¸°_ìš¸ìŒ\": \"BLUE\",\n",
    "    \"ê°œ\": \"BLUE\",\n",
    "    \n",
    "    # ğŸŸ£ ì¼ë°˜ ì†ŒìŒ\n",
    "    \"ì†ŒìŒ_ê°€êµ¬\": \"PURPLE\",\n",
    "    \"ì†ŒìŒ_ë“œëŸ¼\": \"PURPLE\",\n",
    "    \"ì†ŒìŒ_ë¬¸ì†Œë¦¬\": \"PURPLE\",\n",
    "    \"ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬\": \"PURPLE\",\n",
    "    \"ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬\": \"PURPLE\",\n",
    "    \"ì†ŒìŒ_í†µëŒì´\": \"PURPLE\",\n",
    "    \n",
    "    # ê·¸ ì™¸\n",
    "    \"ë°°ê²½ì†ŒìŒ\": \"GRAY\",\n",
    "    \"ì •ì \": \"WHITE\",\n",
    "}\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(f\"ğŸ“š ë¡œë“œëœ í´ë˜ìŠ¤: {len(CLASSES)}ê°œ\")\n",
    "print(f\"   {', '.join(CLASSES[:5])}...ë“±ë“±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c1b24",
   "metadata": {},
   "source": [
    "## ğŸ¼ ìœ í‹¸ë¦¬í‹°: ìŠ¬ë¼ì´ë”© ìœˆë„ìš° & ë¡œê·¸-ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002bef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wav_to_windows(path, sr=SR, win_sec=WIN_SEC, hop_sec=HOP_SEC):\n",
    "    y, sr = librosa.load(path, sr=sr, mono=True)\n",
    "    win = int(sr * win_sec)\n",
    "    hop = int(sr * hop_sec)\n",
    "    if len(y) < win:\n",
    "        y = np.pad(y, (0, win - len(y)))\n",
    "    frames = []\n",
    "    for start in range(0, len(y) - win + 1, hop):\n",
    "        frames.append(y[start:start+win])\n",
    "    return frames\n",
    "\n",
    "def frames_to_logmels(frames, sr=SR, n_mels=N_MELS, fmin=FMIN, fmax=FMAX, shape=SPEC_SHAPE):\n",
    "    specs = []\n",
    "    for fr in frames:\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=fr, sr=sr, n_fft=1024, hop_length=256,\n",
    "            n_mels=n_mels, fmin=fmin, fmax=fmax, power=2.0\n",
    "        )\n",
    "        logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "        zy = shape[0] / logmel.shape[0]\n",
    "        zx = shape[1] / logmel.shape[1]\n",
    "        img = zoom(logmel, (zy, zx), order=1)[..., None]  # (H, W, 1)\n",
    "        specs.append(img.astype(np.float32))\n",
    "    return np.array(specs, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df28c26",
   "metadata": {},
   "source": [
    "## ğŸ§¹ ì „ì²˜ë¦¬: í´ë”â†’ìŠ¬ë¼ì´ìŠ¤â†’ìŠ¤í™íŠ¸ë¡œê·¸ë¨ â†’ NPY ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbdcd7e",
   "metadata": {},
   "source": [
    "## ğŸ§¹ ì „ì²˜ë¦¬: ë°ì´í„° ë¡œë”© (Train + Test í´ë” í†µí•©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e0639a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Š í˜„ì¬ ë°ì´í„° ë¶„í¬ í™•ì¸\n",
      "============================================================\n",
      "\n",
      "TRAIN ì„¸íŠ¸:\n",
      "  ì „ì²´ ìƒ˜í”Œ: 16463\n",
      "  [0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :   239 (  1.5%)\n",
      "  [1] ê°œ                   :   369 (  2.2%)\n",
      "  [2] ë¬¸_ë…¸í¬                :   123 (  0.7%)\n",
      "  [3] ë¬¸_ë„ì–´ë½               :    56 (  0.3%)\n",
      "  [4] ë¬¸_ì´ˆì¸ì¢…               :   262 (  1.6%)\n",
      "  [5] ë°°ê²½ì†ŒìŒ                :  1963 ( 11.9%)\n",
      "  [6] ì†ŒìŒ_ê°€êµ¬               :  1221 (  7.4%)\n",
      "  [7] ì†ŒìŒ_ë“œëŸ¼               :  1753 ( 10.6%)\n",
      "  [8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :  1249 (  7.6%)\n",
      "  [9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :  2096 ( 12.7%)\n",
      "  [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :  1635 (  9.9%)\n",
      "  [11] ì†ŒìŒ_ì²­ì†Œê¸°              :   986 (  6.0%)\n",
      "  [12] ì†ŒìŒ_í†µëŒì´              :  1668 ( 10.1%)\n",
      "  [13] ì•„ê¸°_ìš¸ìŒ               :  1090 (  6.6%)\n",
      "  [14] ì•ˆì „_ë‚™ìƒ               :   510 (  3.1%)\n",
      "  [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :   125 (  0.8%)\n",
      "  [16] ì •ì                   :   153 (  0.9%)\n",
      "  [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :    87 (  0.5%)\n",
      "  [18] í°_ë§í†¤                :   134 (  0.8%)\n",
      "  [19] í°_ì•Œë¦¼                :   308 (  1.9%)\n",
      "  [20] í°_ì „í™”                :   436 (  2.6%)\n",
      "\n",
      "VAL ì„¸íŠ¸:\n",
      "  ì „ì²´ ìƒ˜í”Œ: 4116\n",
      "  [0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :    80 (  1.9%)\n",
      "  [1] ê°œ                   :    90 (  2.2%)\n",
      "  [2] ë¬¸_ë…¸í¬                :    31 (  0.8%)\n",
      "  [3] ë¬¸_ë„ì–´ë½               :    17 (  0.4%)\n",
      "  [4] ë¬¸_ì´ˆì¸ì¢…               :    82 (  2.0%)\n",
      "  [5] ë°°ê²½ì†ŒìŒ                :   474 ( 11.5%)\n",
      "  [6] ì†ŒìŒ_ê°€êµ¬               :   287 (  7.0%)\n",
      "  [7] ì†ŒìŒ_ë“œëŸ¼               :   422 ( 10.3%)\n",
      "  [8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :   346 (  8.4%)\n",
      "  [9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :   514 ( 12.5%)\n",
      "  [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :   395 (  9.6%)\n",
      "  [11] ì†ŒìŒ_ì²­ì†Œê¸°              :   232 (  5.6%)\n",
      "  [12] ì†ŒìŒ_í†µëŒì´              :   420 ( 10.2%)\n",
      "  [13] ì•„ê¸°_ìš¸ìŒ               :   273 (  6.6%)\n",
      "  [14] ì•ˆì „_ë‚™ìƒ               :   113 (  2.7%)\n",
      "  [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :    43 (  1.0%)\n",
      "  [16] ì •ì                   :    45 (  1.1%)\n",
      "  [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :    21 (  0.5%)\n",
      "  [18] í°_ë§í†¤                :    31 (  0.8%)\n",
      "  [19] í°_ì•Œë¦¼                :    82 (  2.0%)\n",
      "  [20] í°_ì „í™”                :   118 (  2.9%)\n",
      "\n",
      "============================================================\n",
      "âš ï¸  ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•˜ë©´ ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë©ë‹ˆë‹¤!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. ë°ì´í„° ë¶„í¬ í™•ì¸\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š í˜„ì¬ ë°ì´í„° ë¶„í¬ í™•ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    npy_path = f\"{CACHE_DIR}/X_{split}.npy\"\n",
    "    y_path = f\"{CACHE_DIR}/y_{split}.npy\"\n",
    "    \n",
    "    if os.path.exists(npy_path):\n",
    "        X = np.load(npy_path)\n",
    "        y = np.load(y_path)\n",
    "        \n",
    "        print(f\"\\n{split.upper()} ì„¸íŠ¸:\")\n",
    "        print(f\"  ì „ì²´ ìƒ˜í”Œ: {len(y)}\")\n",
    "        for i, class_name in enumerate(CLASSES):\n",
    "            count = (y == i).sum()\n",
    "            percentage = (count / len(y)) * 100\n",
    "            print(f\"  [{i}] {class_name:20s}: {count:5d} ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âš ï¸  ë°ì´í„° ë¶ˆê· í˜•ì´ ì‹¬í•˜ë©´ ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë©ë‹ˆë‹¤!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "426ad5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âš–ï¸  ë°ì´í„° ê· í˜• ì¡°ì • ì¤‘...\n",
      "============================================================\n",
      "\n",
      "ğŸ“¥ Train ë°ì´í„° ì ì‘ì  ê· í˜• ì¡°ì •:\n",
      "\n",
      "ğŸ¯ ì ì‘ì  ê· í˜• ì¡°ì • (ìµœì†Œ: 50, ìµœëŒ€: 500)\n",
      "--------------------------------------------------------------------------------\n",
      "  ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :   137 â†’   137 (ìœ ì§€)\n",
      "  ê°œ                   :   266 â†’   266 (ìœ ì§€)\n",
      "  ë¬¸_ë…¸í¬                :    69 â†’    69 (ìœ ì§€)\n",
      "  ë¬¸_ë„ì–´ë½               :    44 â†’    44 (ìœ ì§€)\n",
      "  ë¬¸_ì´ˆì¸ì¢…               :   207 â†’   207 (ìœ ì§€)\n",
      "  ë°°ê²½ì†ŒìŒ                :  1564 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ê°€êµ¬               :   809 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ë“œëŸ¼               :  1396 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ë¬¸ì†Œë¦¬              :   939 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :  1635 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :  1204 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì²­ì†Œê¸°              :   748 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_í†µëŒì´              :  1407 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì•„ê¸°_ìš¸ìŒ               :   876 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì•ˆì „_ë‚™ìƒ               :   386 â†’   386 (ìœ ì§€)\n",
      "  ì•ˆì „_í™”ì¬_ê²½ë³´            :   113 â†’   113 (ìœ ì§€)\n",
      "  ì •ì                   :   112 â†’   112 (ìœ ì§€)\n",
      "  íƒ€ì´ë¨¸_ì•ŒëŒ              :    67 â†’    67 (ìœ ì§€)\n",
      "  í°_ë§í†¤                :    65 â†’    65 (ìœ ì§€)\n",
      "  í°_ì•Œë¦¼                :   153 â†’   153 (ìœ ì§€)\n",
      "  í°_ì „í™”                :   213 â†’   213 (ìœ ì§€)\n",
      "\n",
      "ğŸ“¥ Train ë°ì´í„° ì ì‘ì  ê· í˜• ì¡°ì •:\n",
      "\n",
      "ğŸ¯ ì ì‘ì  ê· í˜• ì¡°ì • (ìµœì†Œ: 50, ìµœëŒ€: 500)\n",
      "--------------------------------------------------------------------------------\n",
      "  ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :   137 â†’   137 (ìœ ì§€)\n",
      "  ê°œ                   :   266 â†’   266 (ìœ ì§€)\n",
      "  ë¬¸_ë…¸í¬                :    69 â†’    69 (ìœ ì§€)\n",
      "  ë¬¸_ë„ì–´ë½               :    44 â†’    44 (ìœ ì§€)\n",
      "  ë¬¸_ì´ˆì¸ì¢…               :   207 â†’   207 (ìœ ì§€)\n",
      "  ë°°ê²½ì†ŒìŒ                :  1564 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ê°€êµ¬               :   809 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ë“œëŸ¼               :  1396 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ë¬¸ì†Œë¦¬              :   939 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :  1635 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :  1204 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_ì²­ì†Œê¸°              :   748 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì†ŒìŒ_í†µëŒì´              :  1407 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì•„ê¸°_ìš¸ìŒ               :   876 â†’   500 (ë‹¤ìš´ìƒ˜í”Œë§)\n",
      "  ì•ˆì „_ë‚™ìƒ               :   386 â†’   386 (ìœ ì§€)\n",
      "  ì•ˆì „_í™”ì¬_ê²½ë³´            :   113 â†’   113 (ìœ ì§€)\n",
      "  ì •ì                   :   112 â†’   112 (ìœ ì§€)\n",
      "  íƒ€ì´ë¨¸_ì•ŒëŒ              :    67 â†’    67 (ìœ ì§€)\n",
      "  í°_ë§í†¤                :    65 â†’    65 (ìœ ì§€)\n",
      "  í°_ì•Œë¦¼                :   153 â†’   153 (ìœ ì§€)\n",
      "  í°_ì „í™”                :   213 â†’   213 (ìœ ì§€)\n",
      "\n",
      "âœ… ì´ ìƒ˜í”Œ: 12410 â†’ 6332\n",
      "\n",
      "âœ… ì´ ìƒ˜í”Œ: 12410 â†’ 6332\n",
      "\n",
      "ğŸ“¥ Validation ë°ì´í„°: (5066, 128, 128, 1) (ì‹¤ì œ ë¶„í¬ ìœ ì§€)\n",
      "\n",
      "ğŸ“¥ Validation ë°ì´í„°: (5066, 128, 128, 1) (ì‹¤ì œ ë¶„í¬ ìœ ì§€)\n",
      "\n",
      "ğŸ’¾ ê· í˜• ë§ì¶˜ Train ë°ì´í„° ì €ì¥ ì™„ë£Œ!\n",
      "   Train (ì›ë³¸):     (12410, 128, 128, 1)\n",
      "   Train (ê· í˜•):     (6332, 128, 128, 1)\n",
      "   Test (ì›ë³¸ ìœ ì§€): (3103, 128, 128, 1)\n",
      "   Val (ì›ë³¸ ìœ ì§€):  (5066, 128, 128, 1)\n",
      "\n",
      "ğŸ“Š ê· í˜• ì¡°ì • í›„ Train ë¶„í¬:\n",
      "--------------------------------------------------------------------------------\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :    137 (  2.2%)\n",
      "   [ 1] ê°œ                   :    266 (  4.2%)\n",
      "   [ 2] ë¬¸_ë…¸í¬                :     69 (  1.1%)\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :     44 (  0.7%)\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :    207 (  3.3%)\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :    500 (  7.9%)\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :    500 (  7.9%)\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :    500 (  7.9%)\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :    500 (  7.9%)\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :    500 (  7.9%)\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :    500 (  7.9%)\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :    500 (  7.9%)\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :    500 (  7.9%)\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :    500 (  7.9%)\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :    386 (  6.1%)\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :    113 (  1.8%)\n",
      "   [16] ì •ì                   :    112 (  1.8%)\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :     67 (  1.1%)\n",
      "   [18] í°_ë§í†¤                :     65 (  1.0%)\n",
      "   [19] í°_ì•Œë¦¼                :    153 (  2.4%)\n",
      "   [20] í°_ì „í™”                :    213 (  3.4%)\n",
      "\n",
      "ğŸ’¾ ê· í˜• ë§ì¶˜ Train ë°ì´í„° ì €ì¥ ì™„ë£Œ!\n",
      "   Train (ì›ë³¸):     (12410, 128, 128, 1)\n",
      "   Train (ê· í˜•):     (6332, 128, 128, 1)\n",
      "   Test (ì›ë³¸ ìœ ì§€): (3103, 128, 128, 1)\n",
      "   Val (ì›ë³¸ ìœ ì§€):  (5066, 128, 128, 1)\n",
      "\n",
      "ğŸ“Š ê· í˜• ì¡°ì • í›„ Train ë¶„í¬:\n",
      "--------------------------------------------------------------------------------\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :    137 (  2.2%)\n",
      "   [ 1] ê°œ                   :    266 (  4.2%)\n",
      "   [ 2] ë¬¸_ë…¸í¬                :     69 (  1.1%)\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :     44 (  0.7%)\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :    207 (  3.3%)\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :    500 (  7.9%)\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :    500 (  7.9%)\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :    500 (  7.9%)\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :    500 (  7.9%)\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :    500 (  7.9%)\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :    500 (  7.9%)\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :    500 (  7.9%)\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :    500 (  7.9%)\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :    500 (  7.9%)\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :    386 (  6.1%)\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :    113 (  1.8%)\n",
      "   [16] ì •ì                   :    112 (  1.8%)\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :     67 (  1.1%)\n",
      "   [18] í°_ë§í†¤                :     65 (  1.0%)\n",
      "   [19] í°_ì•Œë¦¼                :    153 (  2.4%)\n",
      "   [20] í°_ì „í™”                :    213 (  3.4%)\n"
     ]
    }
   ],
   "source": [
    "# 2. ë°ì´í„° ê· í˜• ë§ì¶”ê¸° (ì ì‘ì  ìƒ˜í”Œë§)\n",
    "def balance_dataset_adaptive(X, y, min_samples_threshold=50, max_samples_target=500):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ê· í˜•ì„ ì ì‘ì ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.\n",
    "    - ë„ˆë¬´ ì ì€ í´ë˜ìŠ¤(< min_samples_threshold): ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    - ë§ì€ í´ë˜ìŠ¤: max_samples_targetìœ¼ë¡œ ë‹¤ìš´ìƒ˜í”Œë§\n",
    "    \n",
    "    Args:\n",
    "        X: íŠ¹ì„± ë°ì´í„°\n",
    "        y: ë ˆì´ë¸”\n",
    "        min_samples_threshold: ì´ ê°’ë³´ë‹¤ ì ì€ í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "        max_samples_target: ë§ì€ í´ë˜ìŠ¤ì˜ ìµœëŒ€ ëª©í‘œ ìƒ˜í”Œ ìˆ˜\n",
    "    \"\"\"\n",
    "    unique_classes = np.unique(y)\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ í™•ì¸\n",
    "    class_counts = {cls: (y == cls).sum() for cls in unique_classes}\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì ì‘ì  ê· í˜• ì¡°ì • (ìµœì†Œ: {min_samples_threshold}, ìµœëŒ€: {max_samples_target})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    balanced_X = []\n",
    "    balanced_y = []\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        original_count = len(cls_indices)\n",
    "        \n",
    "        # ìƒ˜í”Œë§ ì „ëµ ê²°ì •\n",
    "        if original_count <= min_samples_threshold:\n",
    "            # ì ì€ í´ë˜ìŠ¤: ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "            selected_indices = cls_indices\n",
    "            strategy = \"ìœ ì§€\"\n",
    "        elif original_count > max_samples_target:\n",
    "            # ë§ì€ í´ë˜ìŠ¤: ë‹¤ìš´ìƒ˜í”Œë§\n",
    "            selected_indices = np.random.choice(cls_indices, max_samples_target, replace=False)\n",
    "            strategy = \"ë‹¤ìš´ìƒ˜í”Œë§\"\n",
    "        else:\n",
    "            # ì¤‘ê°„ í´ë˜ìŠ¤: ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "            selected_indices = cls_indices\n",
    "            strategy = \"ìœ ì§€\"\n",
    "        \n",
    "        balanced_X.append(X[selected_indices])\n",
    "        balanced_y.append(y[selected_indices])\n",
    "        \n",
    "        print(f\"  {CLASSES[cls]:20s}: {original_count:5d} â†’ {len(selected_indices):5d} ({strategy})\")\n",
    "    \n",
    "    balanced_X = np.concatenate(balanced_X, axis=0)\n",
    "    balanced_y = np.concatenate(balanced_y, axis=0)\n",
    "    \n",
    "    # ì…”í”Œ\n",
    "    shuffle_idx = np.random.permutation(len(balanced_y))\n",
    "    balanced_X = balanced_X[shuffle_idx]\n",
    "    balanced_y = balanced_y[shuffle_idx]\n",
    "    \n",
    "    print(f\"\\nâœ… ì´ ìƒ˜í”Œ: {len(y)} â†’ {len(balanced_y)}\")\n",
    "    return balanced_X, balanced_y\n",
    "\n",
    "# Train ë°ì´í„° ê· í˜• ë§ì¶”ê¸°\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âš–ï¸  ë°ì´í„° ê· í˜• ì¡°ì • ì¤‘...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# NPY íŒŒì¼ì—ì„œ ë¡œë“œ\n",
    "X_train = np.load(f\"{CACHE_DIR}/X_train.npy\")\n",
    "y_train = np.load(f\"{CACHE_DIR}/y_train.npy\")\n",
    "\n",
    "print(\"\\nğŸ“¥ Train ë°ì´í„° ì ì‘ì  ê· í˜• ì¡°ì •:\")\n",
    "X_train_balanced, y_train_balanced = balance_dataset_adaptive(\n",
    "    X_train, y_train, \n",
    "    min_samples_threshold=50,  # 50ê°œ ë¯¸ë§Œì€ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    max_samples_target=500     # 500ê°œë¡œ ì œí•œ\n",
    ")\n",
    "\n",
    "# Test ë°ì´í„°ëŠ” ê· í˜• ì¡°ì •í•˜ì§€ ì•ŠìŒ (ì‹¤ì œ ë¶„í¬ ìœ ì§€)\n",
    "X_test = np.load(f\"{CACHE_DIR}/X_test.npy\")\n",
    "y_test = np.load(f\"{CACHE_DIR}/y_test.npy\")\n",
    "\n",
    "# Val ë°ì´í„°ë„ ê· í˜• ì¡°ì •í•˜ì§€ ì•ŠìŒ\n",
    "try:\n",
    "    X_val = np.load(f\"{CACHE_DIR}/X_val.npy\")\n",
    "    y_val = np.load(f\"{CACHE_DIR}/y_val.npy\")\n",
    "    print(f\"\\nğŸ“¥ Validation ë°ì´í„°: {X_val.shape} (ì‹¤ì œ ë¶„í¬ ìœ ì§€)\")\n",
    "except:\n",
    "    X_val, y_val = None, None\n",
    "    print(f\"\\nğŸ“¥ Validation ë°ì´í„°: ì—†ìŒ\")\n",
    "\n",
    "# ê· í˜• ë§ì¶˜ Train ë°ì´í„°ë§Œ ì €ì¥\n",
    "np.save(f\"{CACHE_DIR}/X_train_balanced.npy\", X_train_balanced)\n",
    "np.save(f\"{CACHE_DIR}/y_train_balanced.npy\", y_train_balanced)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ê· í˜• ë§ì¶˜ Train ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"   Train (ì›ë³¸):     {X_train.shape}\")\n",
    "print(f\"   Train (ê· í˜•):     {X_train_balanced.shape}\")\n",
    "print(f\"   Test (ì›ë³¸ ìœ ì§€): {X_test.shape}\")\n",
    "if X_val is not None:\n",
    "    print(f\"   Val (ì›ë³¸ ìœ ì§€):  {X_val.shape}\")\n",
    "\n",
    "# ê· í˜• ì¡°ì • í›„ í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸\n",
    "print(\"\\nğŸ“Š ê· í˜• ì¡°ì • í›„ Train ë¶„í¬:\")\n",
    "print(\"-\" * 80)\n",
    "for ci, cname in enumerate(CLASSES):\n",
    "    count = (y_train_balanced == ci).sum()\n",
    "    percentage = (count / len(y_train_balanced)) * 100 if len(y_train_balanced) > 0 else 0\n",
    "    print(f\"   [{ci:2d}] {cname:20s}: {count:6d} ({percentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "388597ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ ë°ì´í„° ë¡œë“œ ì‹œì‘...\n",
      "\n",
      "================================================================================\n",
      "ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘... (Train/Test ë¶„ë¦¬)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ TRAIN í´ë” ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/jc575gcs03ldzjf4y_2nmltm0000gn/T/ipykernel_9556/3475116199.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(path, sr=sr, mono=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [16] ì •ì                   :  16 íŒŒì¼ âœ“\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :  35 íŒŒì¼ âœ“\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :  35 íŒŒì¼ âœ“\n",
      "   [20] í°_ì „í™”                :  15 íŒŒì¼ âœ“\n",
      "   [20] í°_ì „í™”                :  15 íŒŒì¼ âœ“\n",
      "   [ 1] ê°œ                   :  20 íŒŒì¼ âœ“\n",
      "   [ 1] ê°œ                   :  20 íŒŒì¼ âœ“\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :  80 íŒŒì¼ âœ“\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :  18 íŒŒì¼ âœ“\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :  80 íŒŒì¼ âœ“\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :  18 íŒŒì¼ âœ“\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :  60 íŒŒì¼ âœ“\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :  70 íŒŒì¼ âœ“\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :  52 íŒŒì¼ âœ“\n",
      "   [18] í°_ë§í†¤                :  33 íŒŒì¼ âœ“\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :  22 íŒŒì¼ âœ“\n",
      "   [ 2] ë¬¸_ë…¸í¬                :  32 íŒŒì¼ âœ“\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :  10 íŒŒì¼ âœ“\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :  62 íŒŒì¼ âœ“\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :  27 íŒŒì¼ âœ“\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :  40 íŒŒì¼ âœ“\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :   7 íŒŒì¼ âœ“\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :  21 íŒŒì¼ âœ“\n",
      "   [19] í°_ì•Œë¦¼                :  71 íŒŒì¼ âœ“\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               : 128 íŒŒì¼ âœ“\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :  32 íŒŒì¼ âœ“\n",
      "   TRAIN ì†Œê³„: 851 íŒŒì¼, 15513 ìƒ˜í”Œ\n",
      "\n",
      "ğŸ“ TEST í´ë” ì²˜ë¦¬ ì¤‘...\n",
      "   [16] ì •ì                   :   5 íŒŒì¼ âœ“\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :  17 íŒŒì¼ âœ“\n",
      "   [20] í°_ì „í™”                :  15 íŒŒì¼ âœ“\n",
      "   [ 1] ê°œ                   :   5 íŒŒì¼ âœ“\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :  20 íŒŒì¼ âœ“\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :   4 íŒŒì¼ âœ“\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :  15 íŒŒì¼ âœ“\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :  20 íŒŒì¼ âœ“\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :  18 íŒŒì¼ âœ“\n",
      "   [18] í°_ë§í†¤                :  39 íŒŒì¼ âœ“\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :   8 íŒŒì¼ âœ“\n",
      "   [ 2] ë¬¸_ë…¸í¬                :  12 íŒŒì¼ âœ“\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :   3 íŒŒì¼ âœ“\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :  10 íŒŒì¼ âœ“\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :   8 íŒŒì¼ âœ“\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :  15 íŒŒì¼ âœ“\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :   4 íŒŒì¼ âœ“\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :   6 íŒŒì¼ âœ“\n",
      "   [19] í°_ì•Œë¦¼                :  71 íŒŒì¼ âœ“\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :  32 íŒŒì¼ âœ“\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :  10 íŒŒì¼ âœ“\n",
      "   TEST ì†Œê³„: 337 íŒŒì¼, 5066 ìƒ˜í”Œ\n",
      "\n",
      "================================================================================\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n",
      "   Train:    (12410, 128, 128, 1)\n",
      "   Test:     (3103, 128, 128, 1)\n",
      "   Val:      (5066, 128, 128, 1)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š TRAIN í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\n",
      "--------------------------------------------------------------------------------\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :    137 (  1.1%)\n",
      "   [ 1] ê°œ                   :    266 (  2.1%)\n",
      "   [ 2] ë¬¸_ë…¸í¬                :     69 (  0.6%)\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :     44 (  0.4%)\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :    207 (  1.7%)\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :   1564 ( 12.6%)\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :    809 (  6.5%)\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :   1396 ( 11.2%)\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :    939 (  7.6%)\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :   1635 ( 13.2%)\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :   1204 (  9.7%)\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :    748 (  6.0%)\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :   1407 ( 11.3%)\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :    876 (  7.1%)\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :    386 (  3.1%)\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :    113 (  0.9%)\n",
      "   [16] ì •ì                   :    112 (  0.9%)\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :     67 (  0.5%)\n",
      "   [18] í°_ë§í†¤                :     65 (  0.5%)\n",
      "   [19] í°_ì•Œë¦¼                :    153 (  1.2%)\n",
      "   [20] í°_ì „í™”                :    213 (  1.7%)\n",
      "\n",
      "ğŸ“Š TEST (from train) í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\n",
      "--------------------------------------------------------------------------------\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :     35 (  1.1%)\n",
      "   [ 1] ê°œ                   :     48 (  1.5%)\n",
      "   [ 2] ë¬¸_ë…¸í¬                :      9 (  0.3%)\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :      7 (  0.2%)\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :     55 (  1.8%)\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :    373 ( 12.0%)\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :    206 (  6.6%)\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :    344 ( 11.1%)\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :    221 (  7.1%)\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :    395 ( 12.7%)\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :    304 (  9.8%)\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :    180 (  5.8%)\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :    391 ( 12.6%)\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :    216 (  7.0%)\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :    111 (  3.6%)\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :     27 (  0.9%)\n",
      "   [16] ì •ì                   :     44 (  1.4%)\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :     19 (  0.6%)\n",
      "   [18] í°_ë§í†¤                :     12 (  0.4%)\n",
      "   [19] í°_ì•Œë¦¼                :     42 (  1.4%)\n",
      "   [20] í°_ì „í™”                :     64 (  2.1%)\n",
      "\n",
      "ğŸ“Š VAL (test folder) í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\n",
      "--------------------------------------------------------------------------------\n",
      "   [ 0] ê°€ì „ì œí’ˆ_ì¢…ë£Œ             :    147 (  2.9%)\n",
      "   [ 1] ê°œ                   :    145 (  2.9%)\n",
      "   [ 2] ë¬¸_ë…¸í¬                :     76 (  1.5%)\n",
      "   [ 3] ë¬¸_ë„ì–´ë½               :     22 (  0.4%)\n",
      "   [ 4] ë¬¸_ì´ˆì¸ì¢…               :     82 (  1.6%)\n",
      "   [ 5] ë°°ê²½ì†ŒìŒ                :    500 (  9.9%)\n",
      "   [ 6] ì†ŒìŒ_ê°€êµ¬               :    493 (  9.7%)\n",
      "   [ 7] ì†ŒìŒ_ë“œëŸ¼               :    435 (  8.6%)\n",
      "   [ 8] ì†ŒìŒ_ë¬¸ì†Œë¦¬              :    435 (  8.6%)\n",
      "   [ 9] ì†ŒìŒ_ì•„ì´ë°œì†Œë¦¬            :    580 ( 11.4%)\n",
      "   [10] ì†ŒìŒ_ì–´ë¥¸ë°œì†Œë¦¬            :    522 ( 10.3%)\n",
      "   [11] ì†ŒìŒ_ì²­ì†Œê¸°              :    290 (  5.7%)\n",
      "   [12] ì†ŒìŒ_í†µëŒì´              :    290 (  5.7%)\n",
      "   [13] ì•„ê¸°_ìš¸ìŒ               :    271 (  5.3%)\n",
      "   [14] ì•ˆì „_ë‚™ìƒ               :    126 (  2.5%)\n",
      "   [15] ì•ˆì „_í™”ì¬_ê²½ë³´            :     28 (  0.6%)\n",
      "   [16] ì •ì                   :     42 (  0.8%)\n",
      "   [17] íƒ€ì´ë¨¸_ì•ŒëŒ              :     22 (  0.4%)\n",
      "   [18] í°_ë§í†¤                :     88 (  1.7%)\n",
      "   [19] í°_ì•Œë¦¼                :    195 (  3.8%)\n",
      "   [20] í°_ì „í™”                :    277 (  5.5%)\n",
      "\n",
      "ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def build_split_separate(data_dir):\n",
    "    \"\"\"\n",
    "    Trainê³¼ Test í´ë”ë¥¼ ë¶„ë¦¬í•˜ì—¬ ë°ì´í„° ë¡œë“œ\n",
    "    - train í´ë”: í•™ìŠµìš© (80% í•™ìŠµ, 20% ë‚´ë¶€ í…ŒìŠ¤íŠ¸)\n",
    "    - test í´ë”: ê²€ì¦ìš©\n",
    "    \n",
    "    Args:\n",
    "        data_dir: ìƒìœ„ ë°ì´í„° í´ë” ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        train_data: (X_train, y_train, X_test, y_test)\n",
    "        val_data: (X_val, y_val)\n",
    "    \"\"\"\n",
    "    # í•œê¸€ í´ë˜ìŠ¤ëª… ì •ê·œí™” ë¬¸ì œ ì²˜ë¦¬\n",
    "    norm_classes = set(unicodedata.normalize('NFC', c) for c in CLASSES)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘... (Train/Test ë¶„ë¦¬)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    def load_split_data(split_name):\n",
    "        \"\"\"ê°œë³„ í´ë” ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        X, y = [], []\n",
    "        split_dir = os.path.join(data_dir, split_name)\n",
    "        \n",
    "        if not os.path.exists(split_dir):\n",
    "            print(f\"âš ï¸  í´ë” ì—†ìŒ: {split_dir}\")\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"\\nğŸ“ {split_name.upper()} í´ë” ì²˜ë¦¬ ì¤‘...\")\n",
    "        split_count = 0\n",
    "        \n",
    "        for class_name in os.listdir(split_dir):\n",
    "            # í•œê¸€ ì •ê·œí™”\n",
    "            n_class = unicodedata.normalize('NFC', class_name)\n",
    "            if n_class not in norm_classes:\n",
    "                continue\n",
    "            \n",
    "            # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "            class_idx = CLASSES.index(n_class)\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            \n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            \n",
    "            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ëª¨ë“  ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ\n",
    "            audio_files = glob.glob(os.path.join(class_dir, \"*.wav\")) + \\\n",
    "                         glob.glob(os.path.join(class_dir, \"*.m4a\")) + \\\n",
    "                         glob.glob(os.path.join(class_dir, \"*.flac\"))\n",
    "            \n",
    "            file_count = 0\n",
    "            for audio_path in audio_files:\n",
    "                try:\n",
    "                    frames = wav_to_windows(audio_path)\n",
    "                    specs = frames_to_logmels(frames)\n",
    "                    labels = np.full((specs.shape[0],), class_idx, dtype=np.int64)\n",
    "                    X.append(specs)\n",
    "                    y.append(labels)\n",
    "                    file_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš ï¸  {audio_path}: {str(e)}\")\n",
    "            \n",
    "            if file_count > 0:\n",
    "                print(f\"   [{class_idx:2d}] {n_class:20s}: {file_count:3d} íŒŒì¼ âœ“\")\n",
    "                split_count += file_count\n",
    "        \n",
    "        if not X:\n",
    "            print(f\"âŒ {split_name} í´ë”ì—ì„œ ë¡œë“œëœ ë°ì´í„° ì—†ìŒ!\")\n",
    "            return None, None\n",
    "        \n",
    "        X = np.concatenate(X, axis=0)\n",
    "        y = np.concatenate(y, axis=0)\n",
    "        \n",
    "        print(f\"   {split_name.upper()} ì†Œê³„: {split_count} íŒŒì¼, {len(y)} ìƒ˜í”Œ\")\n",
    "        return X, y\n",
    "    \n",
    "    # Train ë°ì´í„° ë¡œë“œ\n",
    "    X_train_full, y_train_full = load_split_data(\"train\")\n",
    "    \n",
    "    # Test ë°ì´í„° ë¡œë“œ (ê²€ì¦ìš©)\n",
    "    X_val, y_val = load_split_data(\"test\")\n",
    "    \n",
    "    if X_train_full is None:\n",
    "        print(\"âŒ Train ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Train ë°ì´í„°ë¥¼ 80/20ìœ¼ë¡œ ë¶„í• \n",
    "    split_idx = int(0.8 * len(y_train_full))\n",
    "    indices = np.random.permutation(len(y_train_full))\n",
    "    \n",
    "    train_indices = indices[:split_idx]\n",
    "    test_indices = indices[split_idx:]\n",
    "    \n",
    "    X_train = X_train_full[train_indices]\n",
    "    y_train = y_train_full[train_indices]\n",
    "    X_test = X_train_full[test_indices]\n",
    "    y_test = y_train_full[test_indices]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
    "    print(f\"   Train:    {X_train.shape}\")\n",
    "    print(f\"   Test:     {X_test.shape}\")\n",
    "    if X_val is not None:\n",
    "        print(f\"   Val:      {X_val.shape}\")\n",
    "    else:\n",
    "        print(\"   Val:      ì—†ìŒ (test í´ë” ì—†ìŒ)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test), (X_val, y_val)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ (train/test ë¶„ë¦¬)\n",
    "print(\"\\nğŸš€ ë°ì´í„° ë¡œë“œ ì‹œì‘...\\n\")\n",
    "train_data, val_data = build_split_separate(DATA_DIR)\n",
    "\n",
    "if train_data is not None:\n",
    "    X_train, y_train, X_test, y_test = train_data\n",
    "    X_val, y_val = val_data if val_data[0] is not None else (None, None)\n",
    "    \n",
    "    # Train í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸\n",
    "    print(\"\\nğŸ“Š TRAIN í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
    "    print(\"-\" * 80)\n",
    "    for ci, cname in enumerate(CLASSES):\n",
    "        count = (y_train == ci).sum()\n",
    "        percentage = (count / len(y_train)) * 100 if len(y_train) > 0 else 0\n",
    "        print(f\"   [{ci:2d}] {cname:20s}: {count:6d} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Test í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸\n",
    "    print(\"\\nğŸ“Š TEST (from train) í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
    "    print(\"-\" * 80)\n",
    "    for ci, cname in enumerate(CLASSES):\n",
    "        count = (y_test == ci).sum()\n",
    "        percentage = (count / len(y_test)) * 100 if len(y_test) > 0 else 0\n",
    "        print(f\"   [{ci:2d}] {cname:20s}: {count:6d} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Validation í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸\n",
    "    if X_val is not None:\n",
    "        print(\"\\nğŸ“Š VAL (test folder) í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\")\n",
    "        print(\"-\" * 80)\n",
    "        for ci, cname in enumerate(CLASSES):\n",
    "            count = (y_val == ci).sum()\n",
    "            percentage = (count / len(y_val)) * 100 if len(y_val) > 0 else 0\n",
    "            print(f\"   [{ci:2d}] {cname:20s}: {count:6d} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # ë°ì´í„° ì €ì¥\n",
    "    np.save(f\"{CACHE_DIR}/X_train.npy\", X_train)\n",
    "    np.save(f\"{CACHE_DIR}/y_train.npy\", y_train)\n",
    "    np.save(f\"{CACHE_DIR}/X_test.npy\", X_test)\n",
    "    np.save(f\"{CACHE_DIR}/y_test.npy\", y_test)\n",
    "    \n",
    "    if X_val is not None:\n",
    "        np.save(f\"{CACHE_DIR}/X_val.npy\", X_val)\n",
    "        np.save(f\"{CACHE_DIR}/y_val.npy\", y_val)\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ì •ë³´ ì €ì¥\n",
    "    with open(f\"{CACHE_DIR}/classes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(CLASSES, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f35bc1",
   "metadata": {},
   "source": [
    "## ğŸ§  ëª¨ë¸ í•™ìŠµ (EfficientNetB0 ì „ì´í•™ìŠµ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "FINETUNE_AT = 100   # ìƒìœ„ ëª‡ ê°œ ë ˆì´ì–´ ë¯¸ì„¸ì¡°ì •\n",
    "\n",
    "def load_cached_new(use_balanced=True, validation_source=\"test_folder\"):\n",
    "    \"\"\"\n",
    "    ìƒˆë¡œìš´ ë°ì´í„° êµ¬ì¡°ë¡œ ìºì‹œëœ ë°ì´í„° ë¡œë“œ (3ì±„ë„ ë³€í™˜ í¬í•¨)\n",
    "    \n",
    "    Args:\n",
    "        use_balanced: Trueë©´ ê· í˜• ë§ì¶˜ Train ë°ì´í„° ì‚¬ìš©, Falseë©´ ì›ë³¸ ì‚¬ìš©\n",
    "        validation_source: \"test_folder\" (test í´ë”), \"train_split\" (trainì—ì„œ 20% ë¶„í• )\n",
    "    \"\"\"\n",
    "    if use_balanced:\n",
    "        print(\"âœ… ê· í˜• ë§ì¶˜ Train ë°ì´í„°ì…‹ ì‚¬ìš©\")\n",
    "        Xtr = np.load(f\"{CACHE_DIR}/X_train_balanced.npy\")\n",
    "        ytr = np.load(f\"{CACHE_DIR}/y_train_balanced.npy\")\n",
    "    else:\n",
    "        print(\"âš ï¸  ì›ë³¸ Train ë°ì´í„°ì…‹ ì‚¬ìš© (ë¶ˆê· í˜• ê°€ëŠ¥)\")\n",
    "        Xtr = np.load(f\"{CACHE_DIR}/X_train.npy\")\n",
    "        ytr = np.load(f\"{CACHE_DIR}/y_train.npy\")\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„° ì„ íƒ\n",
    "    if validation_source == \"test_folder\":\n",
    "        try:\n",
    "            Xval = np.load(f\"{CACHE_DIR}/X_val.npy\")\n",
    "            yval = np.load(f\"{CACHE_DIR}/y_val.npy\")\n",
    "            print(\"âœ… Test í´ë”ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©\")\n",
    "        except:\n",
    "            print(\"âš ï¸  Test í´ë”ê°€ ì—†ì–´ì„œ Train ë¶„í•  ë°ì´í„°ë¥¼ ê²€ì¦ìœ¼ë¡œ ì‚¬ìš©\")\n",
    "            Xval = np.load(f\"{CACHE_DIR}/X_test.npy\")\n",
    "            yval = np.load(f\"{CACHE_DIR}/y_test.npy\")\n",
    "    else:\n",
    "        Xval = np.load(f\"{CACHE_DIR}/X_test.npy\")\n",
    "        yval = np.load(f\"{CACHE_DIR}/y_test.npy\")\n",
    "        print(\"âœ… Train ë¶„í•  ë°ì´í„°ë¥¼ ê²€ì¦ìœ¼ë¡œ ì‚¬ìš©\")\n",
    "    \n",
    "    # 1ì±„ë„ â†’ 3ì±„ë„ ë³€í™˜ (ImageNet í˜¸í™˜)\n",
    "    print(\"ğŸ”„ 1ì±„ë„ â†’ 3ì±„ë„ ë³€í™˜ ì¤‘...\")\n",
    "    if Xtr.shape[-1] == 1:\n",
    "        Xtr = np.repeat(Xtr, 3, axis=-1)\n",
    "    if Xval.shape[-1] == 1:\n",
    "        Xval = np.repeat(Xval, 3, axis=-1)\n",
    "    \n",
    "    with open(f\"{CACHE_DIR}/classes.json\") as f:\n",
    "        classes = json.load(f)\n",
    "    \n",
    "    print(f\"Train: {Xtr.shape}, Val: {Xval.shape}\")\n",
    "    return (Xtr, ytr), (Xval, yval), classes\n",
    "\n",
    "def build_model_simple(num_classes, input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ CNN ëª¨ë¸ êµ¬ì„±\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # ë‹¨ìˆœí•œ CNN êµ¬ì¡°\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_model_efficientnet(num_classes, input_shape=(128, 128, 3)):\n",
    "    \"\"\"\n",
    "    EfficientNet ê¸°ë°˜ ì „ì´í•™ìŠµ ëª¨ë¸ (ê°€ì¤‘ì¹˜ ì—†ì´)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # EfficientNetB0 ë°±ë³¸ (ê°€ì¤‘ì¹˜ ì—†ì´)\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=None,  # ê°€ì¤‘ì¹˜ ì—†ìŒ\n",
    "        input_tensor=inputs,\n",
    "        pooling=\"avg\"\n",
    "    )\n",
    "    \n",
    "    x = base.output\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(LR),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==== í•™ìŠµ ì‹¤í–‰ ====\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ§  ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê· í˜• ë§ì¶˜ ë°ì´í„° + Test í´ë”ë¥¼ ê²€ì¦ìœ¼ë¡œ ì‚¬ìš©\n",
    "(Xtr, ytr), (Xval, yval), classes = load_cached_new(\n",
    "    use_balanced=True, \n",
    "    validation_source=\"test_folder\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“š í´ë˜ìŠ¤ ìˆ˜: {len(classes)}\")\n",
    "print(f\"ğŸ“Š Train ë¶„í¬: {np.bincount(ytr)}\")\n",
    "print(f\"ğŸ“Š Val ë¶„í¬: {np.bincount(yval)}\")\n",
    "\n",
    "# ë°ì´í„° ì •ê·œí™” (0-255 â†’ 0-1)\n",
    "print(\"ğŸ”„ ë°ì´í„° ì •ê·œí™” ì¤‘...\")\n",
    "Xtr = Xtr.astype(np.float32) / 255.0\n",
    "Xval = Xval.astype(np.float32) / 255.0\n",
    "\n",
    "# ëª¨ë¸ ì„ íƒ (ê°„ë‹¨í•œ CNNìœ¼ë¡œ ì‹œì‘)\n",
    "print(\"ğŸ—ï¸  ëª¨ë¸ êµ¬ì„± ì¤‘...\")\n",
    "try:\n",
    "    # ë¨¼ì € ê°„ë‹¨í•œ CNNìœ¼ë¡œ ì‹œë„\n",
    "    model = build_model_simple(len(classes))\n",
    "    model_type = \"Simple CNN\"\n",
    "    print(\"âœ… Simple CNN ëª¨ë¸ ì‚¬ìš©\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Simple CNN ì‹¤íŒ¨: {e}\")\n",
    "    # ëŒ€ì•ˆìœ¼ë¡œ EfficientNet (ê°€ì¤‘ì¹˜ ì—†ìŒ)\n",
    "    model = build_model_efficientnet(len(classes))\n",
    "    model_type = \"EfficientNet (no weights)\"\n",
    "    print(\"âœ… EfficientNet (ê°€ì¤‘ì¹˜ ì—†ìŒ) ëª¨ë¸ ì‚¬ìš©\")\n",
    "\n",
    "print(f\"ğŸ“ ëª¨ë¸ êµ¬ì¡° ({model_type}):\")\n",
    "print(f\"   ì…ë ¥: {Xtr.shape[1:]}\")\n",
    "print(f\"   ì¶œë ¥: {len(classes)} í´ë˜ìŠ¤\")\n",
    "print(f\"   ì´ íŒŒë¼ë¯¸í„°: {model.count_params():,}\")\n",
    "\n",
    "# ì½œë°± ì„¤ì •\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        f\"{MODEL_DIR}/best.keras\",\n",
    "        save_best_only=True, \n",
    "        monitor=\"val_accuracy\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=7,  # ë” ë§ì€ patience\n",
    "        restore_best_weights=True, \n",
    "        monitor=\"val_accuracy\"\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        patience=3, \n",
    "        factor=0.5, \n",
    "        monitor=\"val_loss\",\n",
    "        min_lr=1e-7\n",
    "    ),\n",
    "]\n",
    "\n",
    "# í•™ìŠµ ì‹œì‘\n",
    "print(f\"\\n\ude80 {model_type} í•™ìŠµ ì‹œì‘...\")\n",
    "history = model.fit(\n",
    "    Xtr, ytr, \n",
    "    validation_data=(Xval, yval),\n",
    "    epochs=NUM_EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    callbacks=callbacks, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "model.save(f\"{MODEL_DIR}/soundlight_efficientnet.keras\")\n",
    "with open(f\"{MODEL_DIR}/classes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(classes, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {MODEL_DIR}/soundlight_efficientnet.keras\")\n",
    "\n",
    "# ìµœì¢… ì„±ëŠ¥ í‰ê°€\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ({model_type}):\")\n",
    "train_loss, train_acc = model.evaluate(Xtr, ytr, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(Xval, yval, verbose=0)\n",
    "print(f\"   Train: Loss={train_loss:.4f}, Accuracy={train_acc:.4f}\")\n",
    "print(f\"   Val:   Loss={val_loss:.4f}, Accuracy={val_acc:.4f}\")\n",
    "\n",
    "# ì„±ëŠ¥ ë¶„ì„\n",
    "if val_acc > 0.8:\n",
    "    print(f\"\\nğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥! ({val_acc:.3f})\")\n",
    "elif val_acc > 0.6:\n",
    "    print(f\"\\nğŸ‘ ê´œì°®ì€ ì„±ëŠ¥ ({val_acc:.3f}). ì¶”ê°€ ìµœì í™” ê°€ëŠ¥\")\n",
    "elif val_acc > 0.4:\n",
    "    print(f\"\\nâš ï¸  ì¤‘ê°„ ì„±ëŠ¥ ({val_acc:.3f}). ê°œì„  í•„ìš”:\")\n",
    "    print(\"   1. ë” ë§ì€ ì—í¬í¬ ë˜ëŠ” ë°ì´í„°\")\n",
    "    print(\"   2. ëª¨ë¸ ë³µì¡ë„ ì¡°ì •\")\n",
    "    print(\"   3. ë°ì´í„° ì „ì²˜ë¦¬ ê°œì„ \")\n",
    "else:\n",
    "    print(f\"\\nâŒ ë‚®ì€ ì„±ëŠ¥ ({val_acc:.3f}). ê·¼ë³¸ì  ê²€í†  í•„ìš”:\")\n",
    "    print(\"   1. ë°ì´í„° í’ˆì§ˆ í™•ì¸\")\n",
    "    print(\"   2. ë ˆì´ë¸” ì •í™•ì„± ê²€ì¦\")\n",
    "    print(\"   3. íŠ¹ì„± ì¶”ì¶œ ë°©ë²• ì¬ê²€í† \")\n",
    "    print(\"   4. í´ë˜ìŠ¤ ê· í˜• ì¬ì¡°ì •\")\n",
    "\n",
    "# í•™ìŠµ íˆìŠ¤í† ë¦¬ ìš”ì•½\n",
    "print(f\"\\nğŸ“ˆ í•™ìŠµ ê²½ê³¼:\")\n",
    "print(f\"   ìµœê³  Train Accuracy: {max(history.history['accuracy']):.4f}\")\n",
    "print(f\"   ìµœê³  Val Accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"   ìµœì¢… ì—í¬í¬: {len(history.history['accuracy'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118c52a",
   "metadata": {},
   "source": [
    "## ğŸ” íŒŒì¼ ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72970294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def specs_from_wav(path):\n",
    "    y, sr = librosa.load(path, sr=SR, mono=True)\n",
    "    win=int(SR*WIN_SEC); hop=int(SR*HOP_SEC)\n",
    "    if len(y) < win: y = np.pad(y, (0, win-len(y)))\n",
    "    specs = []\n",
    "    for st in range(0, len(y)-win+1, hop):\n",
    "        seg = y[st:st+win]\n",
    "        mel = librosa.feature.melspectrogram(y=seg, sr=SR, n_fft=1024, hop_length=256,\n",
    "                                             n_mels=N_MELS, fmin=FMIN, fmax=FMAX, power=2.0)\n",
    "        logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "        zy = SPEC_SHAPE[0] / logmel.shape[0]\n",
    "        zx = SPEC_SHAPE[1] / logmel.shape[1]\n",
    "        img = zoom(logmel, (zy, zx), order=1)[..., None]\n",
    "        specs.append(img.astype(np.float32))\n",
    "    X = np.array(specs, dtype=np.float32)\n",
    "    X = np.repeat(X, 3, axis=-1)\n",
    "    return X\n",
    "\n",
    "def infer_file(wav_path, model_path=f\"{MODEL_DIR}/soundlight_efficientnet.keras\"):\n",
    "    m = tf.keras.models.load_model(model_path)\n",
    "    with open(f\"{MODEL_DIR}/classes.json\") as f:\n",
    "        classes = json.load(f)\n",
    "    X = specs_from_wav(wav_path)\n",
    "    probs = m.predict(X, verbose=0)\n",
    "    mean_prob = probs.mean(axis=0)\n",
    "    idx = int(mean_prob.argmax())\n",
    "    cname = classes[idx]\n",
    "    color = CLASS_TO_COLOR[cname]\n",
    "    print(f\"[FILE] {wav_path} â†’ {cname} | color={color} | conf={mean_prob[idx]:.2f}\")\n",
    "    return cname, color, float(mean_prob[idx])\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "# infer_file(\"sample.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd4ba0",
   "metadata": {},
   "source": [
    "## ğŸ™ ì‹¤ì‹œê°„ ì¶”ë¡  (ë§ˆì´í¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aaab6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "# ê³µí†µ ì„¤ì •ì´ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ë³€ìˆ˜ ì •ì˜\n",
    "if 'SR' not in locals():\n",
    "    print(\"âš ï¸  ê³µí†µ ì„¤ì •ì´ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì…€ 5ë²ˆì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”!\")\n",
    "    SR = 16000\n",
    "    WIN_SEC = 1.0\n",
    "    HOP_SEC = 0.5\n",
    "    N_MELS = 64\n",
    "    FMIN, FMAX = 50, 8000\n",
    "    SPEC_SHAPE = (128, 128)\n",
    "    MODEL_DIR = \"../models\"\n",
    "\n",
    "EMA_ALPHA = 0.6   # ì§€ìˆ˜ì´ë™í‰ê·  ìŠ¤ë¬´ë”©\n",
    "BLOCK = int(SR * HOP_SEC)  # 0.5ì´ˆ ë¸”ë¡\n",
    "\n",
    "def _spec_from_sig(sig):\n",
    "    mel = librosa.feature.melspectrogram(y=sig, sr=SR, n_fft=1024, hop_length=256,\n",
    "                                         n_mels=N_MELS, fmin=FMIN, fmax=FMAX, power=2.0)\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "    zy = SPEC_SHAPE[0]/logmel.shape[0]; zx = SPEC_SHAPE[1]/logmel.shape[1]\n",
    "    img = zoom(logmel, (zy, zx), order=1)[..., None]\n",
    "    img = np.repeat(img, 3, axis=-1)[None, ...].astype(np.float32)\n",
    "    return img\n",
    "\n",
    "def infer_realtime(model_path=f\"{MODEL_DIR}/soundlight_efficientnet.keras\"):\n",
    "    print(\"ğŸ™ï¸ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘...\")\n",
    "    print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path)\n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # í´ë˜ìŠ¤ì™€ ìƒ‰ìƒ ì •ë³´ í™•ì¸\n",
    "    if 'CLASSES' not in locals():\n",
    "        print(\"âŒ CLASSESê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì…€ 5ë²ˆì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“š ë¶„ë¥˜ í´ë˜ìŠ¤: {len(CLASSES)}ê°œ\")\n",
    "    print(f\"   ì²˜ìŒ 5ê°œ: {', '.join(CLASSES[:5])}...\")\n",
    "    \n",
    "    # ì‹¤ì‹œê°„ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ íì™€ ìƒíƒœ\n",
    "    audio_queue = queue.Queue(maxsize=20)\n",
    "    buffer = np.zeros(int(SR * WIN_SEC))\n",
    "    probs_smooth = np.zeros(len(CLASSES))\n",
    "    \n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(f\"ì˜¤ë””ì˜¤ ìƒíƒœ: {status}\")\n",
    "        audio_queue.put(indata.copy())\n",
    "    \n",
    "    print(\"ğŸ“Ÿ ì‹¤ì‹œê°„ ë¶„ë¥˜ ì‹œì‘! (Ctrl+Cë¡œ ì¢…ë£Œ)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        with sd.InputStream(samplerate=SR, channels=1, callback=callback, blocksize=BLOCK):\n",
    "            while True:\n",
    "                if not audio_queue.empty():\n",
    "                    chunk = audio_queue.get().flatten()\n",
    "                    buffer[:-len(chunk)] = buffer[len(chunk):]\n",
    "                    buffer[-len(chunk):] = chunk\n",
    "                    \n",
    "                    # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„± ë° ì˜ˆì¸¡\n",
    "                    spec = _spec_from_sig(buffer)\n",
    "                    probs = m.predict(spec, verbose=0)[0]\n",
    "                    probs_smooth = EMA_ALPHA * probs + (1-EMA_ALPHA) * probs_smooth\n",
    "                    \n",
    "                    # ìµœê³  í™•ë¥  í´ë˜ìŠ¤\n",
    "                    pred_idx = np.argmax(probs_smooth)\n",
    "                    pred_class = CLASSES[pred_idx]\n",
    "                    pred_prob = probs_smooth[pred_idx]\n",
    "                    pred_color = CLASS_TO_COLOR.get(pred_class, \"GRAY\")\n",
    "                    \n",
    "                    # ê²°ê³¼ ì¶œë ¥\n",
    "                    print(f\"ğŸ”Š {pred_class:15s} | í™•ë¥ : {pred_prob:.3f} | ìƒ‰ìƒ: {pred_color}\")\n",
    "                    \n",
    "                time.sleep(0.1)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâœ… ì‹¤ì‹œê°„ ì¶”ë¡  ì¢…ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nâŒ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ (ì£¼ì„ ì²˜ë¦¬):\n",
    "# infer_realtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be3c27",
   "metadata": {},
   "source": [
    "## âœ… ë¹ ë¥¸ ì ê²€ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c23d970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì…€ ì‹¤í–‰ ì™„ë£Œ!\n",
      "ğŸ“Œ ì‚¬ìš© ë°©ë²•:\n",
      "   1. ì…€ 6 (ğŸ” íŒŒì¼ ì¶”ë¡ )ë¶€í„° ì…€ 7 (ğŸ™ ì‹¤ì‹œê°„ ì¶”ë¡ )ê¹Œì§€ ëª¨ë‘ ì‹¤í–‰í•˜ì„¸ìš”\n",
      "   2. ê·¸ ë‹¤ìŒ ì´ ì…€ì„ ì‹¤í–‰í•˜ê±°ë‚˜ ì§ì ‘ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ë°ì´í„°/ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆë‹¤ë©´ ì•„ë˜ë¥¼ ì°¨ë¡€ë¡œ í˜¸ì¶œí•´ë³´ì„¸ìš”.\n",
    "# 1) ì „ì²˜ë¦¬ ë¨¼ì € ì‹¤í–‰ â†’ 2) í•™ìŠµ â†’ 3) íŒŒì¼/ì‹¤ì‹œê°„ ì¶”ë¡ \n",
    "\n",
    "# âš ï¸ ì£¼ì˜: ìœ„ ì…€ë“¤ì„ ë¨¼ì € ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤!\n",
    "# í•„ìš”í•œ í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "# íŒŒì¼ ì¶”ë¡  ì˜ˆì‹œ (ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°):\n",
    "# infer_file(\"path/to/audio.wav\")\n",
    "\n",
    "# ì‹¤ì‹œê°„ ë§ˆì´í¬ ì¶”ë¡  (ëª¨ë¸ì´ ì¤€ë¹„ëœ ê²½ìš°):\n",
    "# infer_realtime()\n",
    "\n",
    "print(\"âœ… ì…€ ì‹¤í–‰ ì™„ë£Œ!\")\n",
    "print(\"ğŸ“Œ ì‚¬ìš© ë°©ë²•:\")\n",
    "print(\"   1. ì…€ 6 (ğŸ” íŒŒì¼ ì¶”ë¡ )ë¶€í„° ì…€ 7 (ğŸ™ ì‹¤ì‹œê°„ ì¶”ë¡ )ê¹Œì§€ ëª¨ë‘ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "print(\"   2. ê·¸ ë‹¤ìŒ ì´ ì…€ì„ ì‹¤í–‰í•˜ê±°ë‚˜ ì§ì ‘ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c3be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc-bootcamp-FP-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
