# 프로젝트 진행 상황 요약 (2025-11-08)

## 핵심 목표
- **하드웨어 시뮬레이션:** 현재 iOS 앱은 '가정 내 소리를 빛으로 변환하는 하드웨어'의 프로토타입 역할을 합니다.
- **상태의 시각화:** 모든 소리(중요 이벤트, 소음, 정적, 배경음)를 각각의 의미에 맞는 빛(색상)으로 표현하는 것을 목표로 합니다. 특히, '정적'이나 '대화' 같은 배경음은 중립적인 회색으로 표시하여, 시스템이 "듣고 있음" 상태임을 명확히 전달합니다.

## 주요 구현 내용
1.  **실시간 소리 분류:**
    - `AVFoundation`으로 마이크 입력을 받아 `SoundAnalysis` 프레임워크와 CoreML 모델(`Koongdeok-soundAI 4.mlmodel`)을 사용하여 실시간으로 소리를 분류합니다.

2.  **UI 구현:**
    - **동적 배경:** 분류된 소리 라벨에 따라 화면 전체의 배경색이 부드럽게 변경됩니다.
    - **데시벨 표시:** 현재 소리 크기(dB)를 실시간으로 표시하여 시각적 피드백을 강화했습니다.
    - **ON/OFF 스위치:** 하드웨어 조작의 느낌을 살린 커스텀 토글 스위치를 구현하여 앱의 분석 시작/중지 상태를 제어합니다.

3.  **분류 알고리즘 및 로직:**
    - **배경 소음 처리:** '정적', '배경소음', '대화'와 같은 소리를 무시하지 않고, 회색 화면으로 명시적으로 표시하여 현재 시스템이 유휴 상태임을 알립니다.
    - **중요 소리 강조:** '화재', '아기 울음' 등 중요한 소리는 즉시 고유의 색상으로 표시되고, 3초 후 다시 중립(회색) 상태로 돌아와 새로운 이벤트를 기다립니다.
    - **라벨 확장:** '대화', '카톡' 라벨을 새로 추가하여 분류 가능한 소리의 범위를 넓혔습니다.

4.  **개발자 편의 기능:**
    - **코드 기반 민감도 조절:** 각 소리 라벨의 탐지 민감도(신뢰도 임계값)를 `SoundClassifier` 클래스 내의 `loadThresholds` 함수에서 개발자가 직접 쉽게 수정하고 관리할 수 있습니다. 이 설정은 `UserDefaults`를 통해 앱 재시작 시에도 유지됩니다.
    - **변경 로그:** `SwiftChangeLog.md` 파일을 생성하여 코드의 주요 변경 이력을 체계적으로 기록합니다.

## 다음 단계 (To-Do)

1.  **사운드 알고리즘 및 모델 사용성 검증:**
    - **목표:** 현재 AI 모델이 각 라벨을 얼마나 정확하게 예측하는지, 설정된 민감도(신뢰도 임계값)가 실제 환경에서 적절하게 작동하는지 검증합니다.
    - **실행 방안:**
        - **테스트 케이스 실행:** 각 라벨에 해당하는 실제 소리(녹음된 파일 또는 실시간 소리)를 입력하여 모델의 예측 결과를 관찰합니다.
        - **결과 기록:** `[소리 라벨] -> [예측된 라벨] / [신뢰도]` 형식으로 결과를 기록하여 모델의 강점과 약점을 파악합니다. (예: "노크 소리 -> 문_노크 / 95%", "재채기 소리 -> 소음_가구 / 88%")
        - **민감도 튜닝:** 검증 결과를 바탕으로, 오탐지가 잦거나 탐지가 잘 안되는 라벨의 신뢰도 임계값을 `loadThresholds` 함수 내에서 수정합니다.

2.  **하드웨어 시뮬레이션 고도화:**
    - **목표:** 현재의 '단색 변화' 방식을 넘어, 실제 하드웨어의 빛 표현 방식을 더 다채롭게 시뮬레이션합니다.
    - **실행 아이디어:**
        - **빛의 패턴:** 소리의 종류나 크기에 따라 빛이 깜빡이거나, 은은하게 퍼지는 등 다양한 애니메이션 효과를 추가합니다.
        - **색상 조합:** 두 가지 이상의 소리가 동시에 감지될 경우(모델이 지원한다면), 색상을 혼합하거나 분할하여 표시하는 방식을 연구합니다.

3.  **사용자 경험(UX) 개선:**
    - **목표:** 앱의 상태 변화를 사용자가 더 직관적으로 인지할 수 있도록 다듬습니다.
    - **실행 아이디어:**
        - **햅틱 피드백:** 중요한 소리(예: 안전 관련)가 감지되었을 때, 시각적 변화와 함께 햅틱 피드백을 제공하여 즉각적인 주의를 유도합니다.
        - **상태 텍스트 개선:** '정적', '배경 소음', '대화 소리' 등 현재 상태를 나타내는 텍스트를 더 명확하고 세련되게 다듬습니다.

4.  **AI 모델 구조 시각화:**
    - **목표:** `Koongdeok-soundAI 4.mlpackage` 모델의 내부 레이어 구조를 다이어그램으로 시각화하여 아키텍처를 명확히 이해합니다.
    - **실행 방안:**
        - Python의 `coremltools` 라이브러리를 사용하는 스크립트를 작성합니다.
        - 스크립트가 모델 파일을 읽어 각 레이어의 정보(이름, 종류, 파라미터 등)를 추출합니다.
        - 추출된 정보를 바탕으로, 다이어그램 생성 언어인 `Mermaid.js` 코드를 생성합니다.
        - 생성된 코드를 Markdown 문서에 붙여넣어 시각적인 모델 구조도를 확인합니다.
    - **필요조건:** 로컬 컴퓨터에 Python 및 `coremltools` 라이브러리 설치.